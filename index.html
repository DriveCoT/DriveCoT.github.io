<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="utf-8">

<!--    <title>V2X-Sim</title>-->
    <title>DriveCoT</title>
    <meta content="width=device-width, initial-scale=1.0" name="viewport">
<!--    <meta content="V2X-Sim" name="description">-->
    <meta content="DriveCoT" name="description">
    <meta content="XXXXX" name="author">
    <!-- css -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/fancybox/jquery.fancybox.css" rel="stylesheet">
    <link href="css/jcarousel.css" rel="stylesheet">
    <link href="css/flexslider.css" rel="stylesheet">
    <link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
    <!-- HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
</head>

<style>
    .flex-caption {
        padding-bottom: 40px; /* Adjust the value as needed */
    }
    .flex-caption p, .flex-caption .author-block {
        margin-bottom: 20px; /* Adjust the value as needed */
    }
</style>

<body>
    <div class="home-page" id="wrapper">
        <!-- start header -->

        <header>
            <div class="navbar navbar-default navbar-static-top">
                <div class="container">
<!--                    <div class="navbar-header">-->
<!--                        <button class="navbar-toggle" data-target=".navbar-collapse" data-toggle="collapse" type="button"><span class="icon-bar"></span> <span class=-->
<!--                        "icon-bar"></span> <span class=-->
<!--                        "icon-bar"></span></button> <a class="navbar-brand" href="index.html"><img alt="logo" src=-->
<!--                        "img/logo-new.png" width="220" >-->
<!--                        &lt;!&ndash;<img alt="logo" src=-->
<!--                        "img/New_York_University-Logo.wine.png" width="250" ><img alt="logo" src=-->
<!--                        "img/SJTU-Logo.png" width="140">&ndash;&gt;-->
<!--                         </a>-->
<!--                    </div>-->

                    <div class="navbar-collapse collapse">
                        <ul class="nav navbar-nav">
                            <li class="active">
                                <a href="index.html">Home</a>
                            </li>
                            <li>
                                <a href="https://arxiv.org/pdf/xxxx.pdf">Paper</a>
                            </li>
                            <li>
                                <a href="https://github.com/tianqi-wang1996/xxx">Code</a>
                            </li>
                            <li>
                                <a href="download.html">Download</a>
                            </li>

                        </ul>
                    </div>
                </div>
            </div>
        </header>
        <!-- end header -->

        <section id="banner">
            <!-- Slider -->
            <div class="flexslider" id="main-slider">
                <ul class="slides">
                    <li>
                        <video loop autoplay muted class="center-full">
                            <source src="img/banner_video.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                        </video>
<!--                        <div class="center-img">-->
<!--                            <img width="50" src="./img/task description.png" alt="A description of your image">-->
<!--                        </div>-->
                        <div class="flex-caption wow fadeInLeft animated" data-wow-animation-name="none">
                            <h3 style="text-transform: none; color: #cae2fc;">DriveCoT</h3>
                            <p> <b> Integrating Chain-of-Thought Reasoning with End-to-End Driving </b> </p>

                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=RIfX6LkAAAAJ&hl" target="_blank">Tianqi Wang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://xieenze.github.io/" target="_blank">Enze Xie</a><sup>2†</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://ruihangchu.com/" target="_blank">Ruihang Chu</a><sup>3</sup>,
                            </span>
                            <span class="author-block">
                                <a href="https://scholar.google.com/citations?user=XboZC1AAAAAJ" target="_blank">Zhenguo
                                    Li</a><sup>2</sup>
                            </span>
                            <span class="author-block">
                                <a href="http://luoping.me/" target="_blank">Ping Luo</a><sup>1†</sup>,
                            </span>
                            <br>

                            <span class="author-block"><sup>1</sup>The University of Hong Kong,</span>
                            <span class="author-block"><sup>2</sup>Huawei Noah's Ark Lab,</span>
                            <span class="author-block"><sup>3</sup>The Chinese University of Hong Kong</span>
                            <span class="eql-cntrb"><small><br><sup>†</sup>Corresponding authors.</small></span>
                        </div>
                    </li>
                </ul>
            </div>
            <!-- end slider -->
        </section>


            <div class="container">
            <div class="row">
                <div class="wow fadeInRight animated" data-wow-animation-name="none">
                    <br>
                    <h2>Abstract (<a href="https://arxiv.org/pdf/2304.01168.pdf" style="color: inherit;">Paper link</a>)</h2>
                    <p style="font-size:16px">
                        The <b>lack of interpretability and controllability</b> in driving decisions hinders real-world deployment for <b>end-to-end driving</b>.
                        In this paper, we collect a comprehensive end-to-end driving dataset named <b>DriveCoT</b>, leveraging the <b>CARLA</b> simulator.
<!--                        It contains <b>sensor data, control decisions, and chain-of-thought labels</b> to indicate the reasoning process.-->
<!--                        We utilize the <b>challenging driving scenarios</b> from the CARLA leaderboard 2.0, which involve high-speed driving and lane-changing,-->
<!--                        and propose a rule-based expert policy to control the vehicle and generate <b>ground truth labels for its reasoning process</b> across-->
<!--                        different driving aspects and the final decisions. In addition, we propose a baseline model called <b>DriveCoT-Agent</b>,-->
<!--                        trained on our dataset, to generate chain-of-thought predictions and final decisions.-->
<!--                        The trained model exhibits strong performance in both open-loop and closed-loop evaluations, demonstrating the effectiveness of our proposed dataset.-->
                    </p>
                    <p style="font-size:16px">
                        DriveCoT provides: (1) the first <b>end-to-end driving dataset</b> containing <b>chain-of-thought thinking process labels</b> and <b>diverse challenging driving scenarios</b>,
                        (2) <b>a rule-based expert policy</b> to handle the challenging scenarios in CARLA leaderboard 2.0 and generate the labels,
                        and (3) <b>a baseline model named DriveCoT-Agent</b> to generate the chain-of-thought predictions and the final driving decisions.
                    </p>

                    <p style="font-size:16px">
                    The DriveCoT dataset comprises <b>1058 scenarios</b> and <b>36K labeled samples</b> (similar to nuScenes), collected at a <b>2 Hz</b> frequency, <b>averaging 17 seconds per scenario</b>.
                    DriveCoT contains <b>sensor data</b> such as <b>images from multi-view cameras</b> and <b>lidar point clouds</b> from ego vehicle, and the expert policy's <b>reasoning process</b> and <b>decisions</b> as driving understanding labels in a <b>chain-of-thought</b> format.
                    </p>
                    <br>
                    <h2>End-to-End v.s. Modular Driving</h2>
                    <p style="font-size:16px">
<!--                        End-to-End Driving: <br>-->
<!--                        Pros: system simplicity and competitive driving performance;-->
<!--                        Cons: lack of interpretability and controllability<br>-->
<!--                        Thus hinder its real-world deployment.-->
                        End-to-end driving has made significant progress in recent years, demonstrating <b>benefits such as system simplicity
                        and competitive driving performance</b> under both open-loop and closed-loop settings.
                        Nevertheless, <b>the lack of interpretability and controllability</b> in its driving decisions hinders real-world deployment for end-to-end driving systems.
                    </p>
                    <div class="center-img">
                            <img width="700" src="./img/e2e_vs_modular.png" alt="A description of your image">
                    </div>

                    <br>
                    <p style="font-size:16px">
                        In DriveCoT, we additionally annotate the <b>chain-of-thought thinking process</b> to get the final driving decisions,
                        thus providing <b>interpretability and controllability</b> for end-to-end driving methods.
                    </p>
                    <div class="center-img">
                            <img width="800" src="./img/task description.png" alt="A description of your image">
                    </div>

                    <br>
                    <h2>Driving Scenarios</h2>
                    <p style="font-size:16px">
                        The driving scenarios in DriveCoT include <b>challenging situations such as high-speed driving and lane-changing</b>,
                        and are collected in the latest CARLA large map Town12.
                        Specifically, we adapt most of the designed challenging scenarios in <b>CARLA Leaderboard 2.0</b>
                        but ignore those that force an overtaking behavior, which we plan to extend in our future work.
                    </p>
                    <div class="center-img">
                            <img width="1000" src="./img/sceario_type.png" alt="A description of your image">
                    </div>
                    <br>
                    <p style="font-size:16px">
                        The scenario-level statistics of DriveCoT dataset are shown below:
                    </p>
                    <div class="center-img">
                            <img width="600" src="./img/stats_scene.png" alt="A description of your image">
                    </div>

                    <br>
                    <h2>Expert Policy</h2>
                    <p style="font-size:16px">
                        We propose a <b>rule-based expert policy</b> that has access to the ground truth states of the simulator.
                        The expert policy <b>controls the ego vehicle</b> to handle the designed scenarios and complete the routes.
                        Additionally, <b>the thinking process of the expert policy is recorded</b> to serve as the chain-of-thought labels of
                        the proposed DriveCoT dataset. The chain-of-thought process includes checking <b>potential hazards with red traffic light</b>, <b>stop sign</b>,
                        <b>potential collisions with surrounding vehicles and pedestrians</b>, and <b>ego's relation to the ahead vehicle in the same driving lane</b>.
                        The final decisions include the <b>target speed for longitudinal control</b> and <b>future planned waypoints for lateral control</b>.
                    </p>
                    <div class="center-img">
                            <img width="800" src="./img/supple_expert_collision.png" alt="A description of your image">
                    </div>

                    <br>
                    <h2>Dataset Annotation</h2>
                    <p style="font-size:16px">
                        <b>Visualization of the collected data in DriveCoT dataset.</b>
                        <br>
                        <b>The second blue text line</b> in the video shows <b>the chain-of-thought thinking labels</b> and <b>the final speed decisions</b> from the expert policy.
                        The yellow dot in the video is <b>the additional navigation inputs</b> to indicate directions.
                        The blue dots in the  video are <b>the future planned waypoints</b> generated by the expert policy to determine the steering control.
                    </p>
                    <video loop autoplay muted class="center-full" style="width: 90%;">
                            <source src="img/expert_policy_vis.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                    </video>
                    <br>
                    <p style="font-size:16px">
                        We also provide <b>detailed annotations in text-form</b> besides the simplified classification and regression results on each chain-of-thought task.
                        The text annotations are diversified by ChatGPT to vary sentence structures for each CoT aspect.
                    </p>
                    <div class="center-img">
                            <img width="800" src="./img/supple_text_annotation_full.png" alt="A description of your image">
                    </div>

                    <br>
                    <h2>DriveCoT-Agent</h2>
                    <p style="font-size:16px">
                        We propose a baseline model called <b>DriveCoT-Agent</b> as shown below.
                        This model processes <b>video inputs</b> from <b>six surrounding cameras</b> of different views over a specified time period.
                        It predicts <b>chain-of-thought aspects</b> such as potential collisions, traffic light and stop sign hazards,
                        and the relation to the vehicle ahead, to determine the <b>target speed</b>. The <b>future planned waypoints</b> generated via a GRU (Gated Recurrent Unit) layer.
                    </p>
                    <div class="center-img">
                            <img width="800" src="./img/model.png" alt="A description of your image">
                    </div>
                    <br>
                    <p style="font-size:16px">
                        Additionally, we propose a <b>chain-of-thought process</b> to <b>obtain the final target speed based on network outputs</b>.
                        Specifically, it first <b>considers the potential hazards</b> that may trigger <b>emergency brake</b>.
                        If no such hazards are identified, it then evaluates <b>ego's relation to the ahead vehicle</b> and <b>the road structure</b>.
                        This chain-of-thought process decomposes the end-to-end driving into <b>simple</b>, <b>distinctive</b> tasks, enhancing both
                        <b>interpretability</b> and <b>controllability</b>.
                    </p>
                    <div class="center-img">
                            <img width="800" src="./img/CoT.png" alt="A description of your image">
                    </div>

                    <br>
                    <h2>Experiment</h2>
                    <p style="font-size:16px">
                        Evaluation on the validation split of DriveCoT dataset.<br>
                        The second blue text line: ground truth.<br>
                        The third text line: model predictions (marked as <span style="color: green;">green when matches</span>
                        the <span style="color: blue;">GT</span>, <span style="color: darkred;">otherwise as red</span>)
                        <span style="color: #e3e032;">Yellow</span> dot: target point. <span style="color: blue;">Blue</span> dots: gt waypoints.
                        <span style="color: green;">Green</span>/<span style="color: darkred;">Red</span> dots: predicted waypoints.
                    </p>
                    <video loop autoplay muted class="center-full" style="width: 90%;">
                            <source src="img/open_loop.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                    </video>
                    <br>
                    <p style="font-size:16px">
                        Closed-loop testing <br>
                        <span style="color: #e3e032;">Yellow</span> dot: target point. <span style="color: green;">Green</span> dots: predicted waypoints.
                    </p>
                    <video loop autoplay muted class="center-full" style="width: 95%;">
                            <source width="400" src="img/closed_loop.mp4" type="video/mp4">
                                Your browser does not support the video tag.
                    </video>



                
                    <h2>Citation</h2>
                    <p style="font-size:16px"> If you find the dataset helpful, please consider citing us.</p>
                    <pre>
    @article{Wang_2024_DriveCoT,
        title = {DriveCoT: Integrating Chain-of-Thought Reasoning with End-to-End Driving},
        author = {Wang, Tianqi and Xie, Enze and Chu, Ruihang and Li, Zhenguo and Ping, Luo},
        journal = {arXiv preprint arXiv:xxxxx},
        year = {2024}
    }
                    </pre>

                </div>
                </div>
            </div>


<!--        <section class="hero-text">-->
<!--                <div class="container">-->
<!--                    <div class="row">-->
<!--                        <div class="about wow fadeInRight animated">-->
<!--                            <h2 style="color: white;">Motion Showcase</h2>-->
<!--                            <div class="center-img">-->
<!--                                <img width="1200" src="./img/motion_case/motion_case1.jpg" alt="A description of your image">-->
<!--                        </div>-->
<!--                        </div>-->

<!--                    </div>-->
<!--                </div>-->
<!--        </section>-->



        </div>





    <footer>
        <div id="sub-footer">
            <div class="container">
                <div class="row">
                    <div class="col-lg-6">
                        <div class="copyright">
                            <p><span>&copy; HKU MMLab and Huawei Noah's Ark Lab 2024 All rights reserved.
                                </span> </p>
                        </div>
                    </div>


                    <div class="col-lg-6">
                        <ul class="social-network">
                            <li>
                                <a class="fa fa-github" data-placement="top" href="https://github.com/tianqi-wang1996/DriveCoT/" style="font-style: italic" title="GitHub">
                                </a>
                            </li>
                            <li>
                                <a class="fa fa-external-link" data-placement="top" href="http://luoping.me/" style="font-style: italic" title="Lab Website"></a>
                            </li>

                        </ul>
                    </div>
                </div>
            </div>
        </div>
    </footer>


    <a class="scrollup fa fa-angle-up active" href="#" style="font-style: italic"></a>
    <!-- javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/jquery.js"></script>
    <script src="js/jquery.easing.1.3.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.fancybox.pack.js"></script>
    <script src="js/jquery.fancybox-media.js"></script>
    <script src="js/portfolio/jquery.quicksand.js"></script>
    <script src="js/portfolio/setting.js"></script>
    <script src="js/jquery.flexslider.js"></script>
    <script src="js/animate.js"></script>
    <script src="js/custom.js"></script>
    <script src="js/owl-carousel/owl.carousel.js"></script>
</body>

</html>